# ChatGPT / LLM é›†æˆ

## æ¦‚è¿°

æœ¬æ–‡è¯¦ç»†ä»‹ç»å¦‚ä½•åœ¨å‰ç«¯åº”ç”¨ä¸­é›†æˆ ChatGPT å’Œå…¶ä»–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼ŒåŒ…æ‹¬ API ä½¿ç”¨ã€æµå¼å“åº”å¤„ç†ã€å®é™…åº”ç”¨æ¡ˆä¾‹ç­‰ã€‚

---

## OpenAI API ä½¿ç”¨

### API Key é…ç½®

#### 1. è·å– API Key

1. è®¿é—® [OpenAI Platform](https://platform.openai.com/)
2. æ³¨å†Œ/ç™»å½•è´¦å·
3. è¿›å…¥ API Keys é¡µé¢
4. åˆ›å»ºæ–°çš„ API Key

#### 2. å®‰å…¨å­˜å‚¨

```javascript
// âŒ é”™è¯¯ï¼šç›´æ¥åœ¨å‰ç«¯ä»£ç ä¸­ä½¿ç”¨
const OPENAI_API_KEY = 'sk-xxx'; // æ°¸è¿œä¸è¦è¿™æ ·åšï¼

// âœ… æ­£ç¡®ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆåç«¯ï¼‰
// .env.local
OPENAI_API_KEY=sk-xxx

// åç«¯ä»£ç 
const apiKey = process.env.OPENAI_API_KEY;
```

#### 3. åç«¯ä»£ç†è®¾ç½®

```javascript
// Next.js API Route: pages/api/chat.js
export default async function handler(req, res) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  const { messages } = req.body;

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-4',
        messages
      })
    });

    const data = await response.json();
    res.status(200).json(data);
  } catch (error) {
    console.error('OpenAI API Error:', error);
    res.status(500).json({ error: 'Internal server error' });
  }
}
```

### Chat Completions API

#### åŸºç¡€è°ƒç”¨

```javascript
/**
 * åŸºç¡€çš„ Chat Completions API è°ƒç”¨
 */
async function chat(messages) {
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${API_KEY}`
    },
    body: JSON.stringify({
      model: 'gpt-4',
      messages: messages,
      temperature: 0.7,        // éšæœºæ€§ï¼š0-2ï¼Œè¶Šä½è¶Šç¡®å®š
      max_tokens: 2000,        // æœ€å¤§è¾“å‡º token æ•°
      top_p: 1,                // æ ¸é‡‡æ ·
      frequency_penalty: 0,    // é¢‘ç‡æƒ©ç½šï¼š-2.0 åˆ° 2.0
      presence_penalty: 0      // å­˜åœ¨æƒ©ç½šï¼š-2.0 åˆ° 2.0
    })
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.error.message);
  }

  const data = await response.json();
  return data.choices[0].message.content;
}

// ä½¿ç”¨ç¤ºä¾‹
const messages = [
  {
    role: 'system',
    content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‰ç«¯å¼€å‘åŠ©æ‰‹'
  },
  {
    role: 'user',
    content: 'è§£é‡Šä¸€ä¸‹ React çš„ useEffect'
  }
];

const reply = await chat(messages);
console.log(reply);
```

#### å‚æ•°è¯¦è§£

```javascript
const requestBody = {
  // å¿…éœ€å‚æ•°
  model: 'gpt-4',              // æ¨¡å‹ï¼šgpt-4, gpt-3.5-turbo ç­‰
  messages: [],                // æ¶ˆæ¯æ•°ç»„

  // å¯é€‰å‚æ•°
  temperature: 0.7,            // æ¸©åº¦ï¼š0-2
                               // 0: ç¡®å®šæ€§å¼ºï¼Œé€‚åˆä»£ç ç”Ÿæˆ
                               // 0.7: å¹³è¡¡åˆ›é€ åŠ›å’Œå‡†ç¡®æ€§
                               // 1.5+: é«˜åˆ›é€ åŠ›ï¼Œå¯èƒ½ä¸å‡†ç¡®

  max_tokens: 2000,            // æœ€å¤§è¾“å‡º token æ•°

  top_p: 1,                    // æ ¸é‡‡æ ·ï¼š0-1
                               // ä¸ temperature äºŒé€‰ä¸€ä½¿ç”¨

  n: 1,                        // ç”Ÿæˆå‡ ä¸ªå›å¤

  stop: ['\n', 'END'],        // åœæ­¢åºåˆ—

  presence_penalty: 0,         // å­˜åœ¨æƒ©ç½šï¼š-2.0 åˆ° 2.0
                               // æ­£å€¼é¼“åŠ±è°ˆè®ºæ–°è¯é¢˜

  frequency_penalty: 0,        // é¢‘ç‡æƒ©ç½šï¼š-2.0 åˆ° 2.0
                               // æ­£å€¼é™ä½é‡å¤å†…å®¹

  user: 'user-123'            // ç”¨æˆ·æ ‡è¯†ï¼ˆç”¨äºç›‘æ§å’Œé™æµï¼‰
};
```

#### æ¶ˆæ¯æ ¼å¼

```javascript
const messages = [
  // 1. System Messageï¼ˆç³»ç»Ÿæ¶ˆæ¯ï¼‰
  // å®šä¹‰ AI çš„è§’è‰²å’Œè¡Œä¸º
  {
    role: 'system',
    content: 'ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„å‰ç«¯æ¶æ„å¸ˆï¼Œæ“…é•¿ Reactã€Vue å’Œæ€§èƒ½ä¼˜åŒ–ã€‚'
  },

  // 2. User Messageï¼ˆç”¨æˆ·æ¶ˆæ¯ï¼‰
  // ç”¨æˆ·çš„è¾“å…¥
  {
    role: 'user',
    content: 'å¦‚ä½•ä¼˜åŒ– React åº”ç”¨çš„é¦–å±åŠ è½½é€Ÿåº¦ï¼Ÿ'
  },

  // 3. Assistant Messageï¼ˆåŠ©æ‰‹æ¶ˆæ¯ï¼‰
  // AI çš„å›å¤ï¼Œç”¨äºå¤šè½®å¯¹è¯
  {
    role: 'assistant',
    content: 'å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ä¼˜åŒ–...'
  },

  // ç»§ç»­å¯¹è¯
  {
    role: 'user',
    content: 'èƒ½ç»™ä¸ªä»£ç ç¤ºä¾‹å—ï¼Ÿ'
  }
];
```

### æµå¼å“åº”ï¼ˆSSEï¼‰

#### å‰ç«¯å®ç°

```javascript
/**
 * æµå¼è·å– ChatGPT å“åº”
 */
async function streamChat(messages, onChunk, onComplete, onError) {
  try {
    const response = await fetch('/api/chat/stream', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({ messages })
    });

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }

    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let buffer = '';

    while (true) {
      const { done, value } = await reader.read();

      if (done) {
        onComplete?.();
        break;
      }

      // è§£ç æ•°æ®å—
      buffer += decoder.decode(value, { stream: true });

      // æŒ‰è¡Œåˆ†å‰²
      const lines = buffer.split('\n');

      // ä¿ç•™æœ€åä¸€ä¸ªä¸å®Œæ•´çš„è¡Œ
      buffer = lines.pop() || '';

      for (const line of lines) {
        const trimmed = line.trim();

        if (!trimmed || trimmed === 'data: [DONE]') {
          continue;
        }

        if (trimmed.startsWith('data: ')) {
          try {
            const data = JSON.parse(trimmed.slice(6));
            const content = data.choices[0]?.delta?.content;

            if (content) {
              onChunk(content);
            }
          } catch (e) {
            console.error('Parse error:', e, trimmed);
          }
        }
      }
    }
  } catch (error) {
    console.error('Stream error:', error);
    onError?.(error);
  }
}

// ä½¿ç”¨ç¤ºä¾‹
let fullResponse = '';

await streamChat(
  messages,
  // onChunk: æ¯æ¬¡æ¥æ”¶åˆ°æ–°å†…å®¹
  (chunk) => {
    fullResponse += chunk;
    console.log('æ”¶åˆ°:', chunk);
    // æ›´æ–° UI
  },
  // onComplete: å®Œæˆ
  () => {
    console.log('å®Œæ•´å“åº”:', fullResponse);
  },
  // onError: é”™è¯¯å¤„ç†
  (error) => {
    console.error('é”™è¯¯:', error);
  }
);
```

#### åç«¯å®ç°ï¼ˆNext.jsï¼‰

```javascript
// pages/api/chat/stream.js
export default async function handler(req, res) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  const { messages } = req.body;

  // è®¾ç½® SSE å“åº”å¤´
  res.setHeader('Content-Type', 'text/event-stream');
  res.setHeader('Cache-Control', 'no-cache, no-transform');
  res.setHeader('Connection', 'keep-alive');

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-4',
        messages,
        stream: true  // å¼€å¯æµå¼å“åº”
      })
    });

    if (!response.ok) {
      throw new Error(`OpenAI API error: ${response.status}`);
    }

    // è½¬å‘æµ
    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
      const { done, value } = await reader.read();

      if (done) {
        res.write('data: [DONE]\n\n');
        res.end();
        break;
      }

      const chunk = decoder.decode(value);
      res.write(chunk);
    }
  } catch (error) {
    console.error('Stream error:', error);
    res.write(`data: ${JSON.stringify({ error: error.message })}\n\n`);
    res.end();
  }
}

// ç¦ç”¨ Next.js çš„è‡ªåŠ¨ body è§£æ
export const config = {
  api: {
    bodyParser: true,
    responseLimit: false
  }
};
```

### Function Calling

Function Calling å…è®¸ GPT è°ƒç”¨ä½ å®šä¹‰çš„å‡½æ•°ï¼Œå®ç°æ›´å¤æ‚çš„äº¤äº’ã€‚

#### å®šä¹‰å‡½æ•°

```javascript
const functions = [
  {
    name: 'get_weather',
    description: 'è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯',
    parameters: {
      type: 'object',
      properties: {
        city: {
          type: 'string',
          description: 'åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·'
        },
        unit: {
          type: 'string',
          enum: ['celsius', 'fahrenheit'],
          description: 'æ¸©åº¦å•ä½'
        }
      },
      required: ['city']
    }
  },
  {
    name: 'search_products',
    description: 'æœç´¢å•†å“',
    parameters: {
      type: 'object',
      properties: {
        keyword: {
          type: 'string',
          description: 'æœç´¢å…³é”®è¯'
        },
        category: {
          type: 'string',
          description: 'å•†å“åˆ†ç±»'
        },
        priceRange: {
          type: 'object',
          properties: {
            min: { type: 'number' },
            max: { type: 'number' }
          }
        }
      },
      required: ['keyword']
    }
  }
];
```

#### å®ç°å‡½æ•°

```javascript
// å®é™…çš„å‡½æ•°å®ç°
const availableFunctions = {
  get_weather: async ({ city, unit = 'celsius' }) => {
    // è°ƒç”¨å¤©æ°” API
    const response = await fetch(`https://api.weather.com/${city}`);
    const data = await response.json();
    return {
      city,
      temperature: data.temp,
      unit,
      condition: data.condition
    };
  },

  search_products: async ({ keyword, category, priceRange }) => {
    // è°ƒç”¨å•†å“æœç´¢ API
    const params = new URLSearchParams({
      q: keyword,
      category: category || '',
      minPrice: priceRange?.min || 0,
      maxPrice: priceRange?.max || 99999
    });

    const response = await fetch(`/api/products?${params}`);
    const data = await response.json();
    return data.products;
  }
};
```

#### ä½¿ç”¨ Function Calling

```javascript
async function chatWithFunctions(messages) {
  // ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šGPT å†³å®šæ˜¯å¦è°ƒç”¨å‡½æ•°
  let response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${API_KEY}`
    },
    body: JSON.stringify({
      model: 'gpt-4',
      messages,
      functions,
      function_call: 'auto'  // 'auto' | 'none' | { name: 'function_name' }
    })
  });

  let data = await response.json();
  let message = data.choices[0].message;

  // æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å‡½æ•°
  if (message.function_call) {
    const functionName = message.function_call.name;
    const functionArgs = JSON.parse(message.function_call.arguments);

    console.log(`è°ƒç”¨å‡½æ•°: ${functionName}`);
    console.log('å‚æ•°:', functionArgs);

    // æ‰§è¡Œå‡½æ•°
    const functionResponse = await availableFunctions[functionName](functionArgs);

    // å°†å‡½æ•°ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
    messages.push(message);  // GPT çš„ function_call æ¶ˆæ¯
    messages.push({
      role: 'function',
      name: functionName,
      content: JSON.stringify(functionResponse)
    });

    // ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šè®© GPT åŸºäºå‡½æ•°ç»“æœç”Ÿæˆå›å¤
    response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-4',
        messages
      })
    });

    data = await response.json();
    message = data.choices[0].message;
  }

  return message.content;
}

// ä½¿ç”¨ç¤ºä¾‹
const messages = [
  {
    role: 'system',
    content: 'ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥æŸ¥è¯¢å¤©æ°”å’Œæœç´¢å•†å“ã€‚'
  },
  {
    role: 'user',
    content: 'åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'
  }
];

const reply = await chatWithFunctions(messages);
console.log(reply);
// GPT ä¼šè‡ªåŠ¨è°ƒç”¨ get_weather å‡½æ•°ï¼Œç„¶ååŸºäºç»“æœå›ç­”
// è¾“å‡ºï¼š"åŒ—äº¬ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦ 25Â°Cã€‚"
```

### Vision APIï¼ˆå›¾ç‰‡ç†è§£ï¼‰

GPT-4 Vision å¯ä»¥ç†è§£å›¾ç‰‡å†…å®¹ã€‚

```javascript
/**
 * å›¾ç‰‡ç†è§£
 */
async function analyzeImage(imageUrl, question) {
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${API_KEY}`
    },
    body: JSON.stringify({
      model: 'gpt-4-vision-preview',
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: question || 'è¯·æè¿°è¿™å¼ å›¾ç‰‡'
            },
            {
              type: 'image_url',
              image_url: {
                url: imageUrl,
                detail: 'high'  // 'low' | 'high' | 'auto'
              }
            }
          ]
        }
      ],
      max_tokens: 500
    })
  });

  const data = await response.json();
  return data.choices[0].message.content;
}

// ä½¿ç”¨ç¤ºä¾‹
const description = await analyzeImage(
  'https://example.com/screenshot.png',
  'è¿™ä¸ªç•Œé¢æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿå¦‚ä½•æ”¹è¿›ï¼Ÿ'
);

console.log(description);
```

#### ä¸Šä¼ æœ¬åœ°å›¾ç‰‡

```javascript
/**
 * å°†å›¾ç‰‡è½¬æ¢ä¸º base64
 */
function imageToBase64(file) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => resolve(reader.result);
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
}

/**
 * åˆ†ææœ¬åœ°å›¾ç‰‡
 */
async function analyzeLocalImage(file, question) {
  const base64Image = await imageToBase64(file);

  const response = await fetch('/api/vision', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      image: base64Image,
      question
    })
  });

  const data = await response.json();
  return data.result;
}

// ä½¿ç”¨ç¤ºä¾‹ï¼ˆReactï¼‰
function ImageAnalyzer() {
  const [result, setResult] = useState('');

  const handleFileChange = async (e) => {
    const file = e.target.files[0];
    if (file) {
      const description = await analyzeLocalImage(
        file,
        'è¿™å¼ å›¾ç‰‡æ˜¾ç¤ºçš„æ˜¯ä»€ä¹ˆï¼Ÿ'
      );
      setResult(description);
    }
  };

  return (
    <div>
      <input type="file" accept="image/*" onChange={handleFileChange} />
      <p>{result}</p>
    </div>
  );
}
```

---

## å‰ç«¯é›†æˆå®è·µ

### React ä¸­é›†æˆ ChatGPT

#### å®Œæ•´çš„èŠå¤©ç»„ä»¶

```jsx
import React, { useState, useRef, useEffect } from 'react';
import { marked } from 'marked';
import hljs from 'highlight.js';
import 'highlight.js/styles/github-dark.css';

// é…ç½® marked
marked.setOptions({
  highlight: (code, lang) => {
    if (lang && hljs.getLanguage(lang)) {
      return hljs.highlight(code, { language: lang }).value;
    }
    return hljs.highlightAuto(code).value;
  },
  breaks: true,
  gfm: true
});

function ChatApp() {
  const [messages, setMessages] = useState([
    {
      role: 'system',
      content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‰ç«¯å¼€å‘åŠ©æ‰‹'
    }
  ]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);
  const [streamingContent, setStreamingContent] = useState('');
  const messagesEndRef = useRef(null);

  // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages, streamingContent]);

  // å‘é€æ¶ˆæ¯
  const sendMessage = async () => {
    if (!input.trim() || loading) return;

    const userMessage = {
      role: 'user',
      content: input.trim()
    };

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    const newMessages = [...messages, userMessage];
    setMessages(newMessages);
    setInput('');
    setLoading(true);
    setStreamingContent('');

    try {
      // è°ƒç”¨æµå¼ API
      await streamChat(
        newMessages,
        (chunk) => {
          setStreamingContent(prev => prev + chunk);
        },
        () => {
          // å®Œæˆæ—¶æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
          setMessages(prev => [
            ...prev,
            {
              role: 'assistant',
              content: streamingContent
            }
          ]);
          setStreamingContent('');
          setLoading(false);
        },
        (error) => {
          console.error('Error:', error);
          setMessages(prev => [
            ...prev,
            {
              role: 'assistant',
              content: 'æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚'
            }
          ]);
          setStreamingContent('');
          setLoading(false);
        }
      );
    } catch (error) {
      console.error('Send message error:', error);
      setLoading(false);
      setStreamingContent('');
    }
  };

  // æµå¼å“åº”å‡½æ•°
  const streamChat = async (msgs, onChunk, onComplete, onError) => {
    try {
      const response = await fetch('/api/chat/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ messages: msgs })
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) {
          onComplete();
          break;
        }

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';

        for (const line of lines) {
          const trimmed = line.trim();
          if (!trimmed || trimmed === 'data: [DONE]') continue;

          if (trimmed.startsWith('data: ')) {
            try {
              const data = JSON.parse(trimmed.slice(6));
              const content = data.choices[0]?.delta?.content;
              if (content) onChunk(content);
            } catch (e) {
              console.error('Parse error:', e);
            }
          }
        }
      }
    } catch (error) {
      onError(error);
    }
  };

  return (
    <div className="chat-container">
      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      <div className="messages">
        {messages.slice(1).map((msg, index) => (
          <Message key={index} message={msg} />
        ))}

        {/* æµå¼å“åº”ä¸­çš„æ¶ˆæ¯ */}
        {streamingContent && (
          <Message
            message={{
              role: 'assistant',
              content: streamingContent
            }}
            streaming
          />
        )}

        <div ref={messagesEndRef} />
      </div>

      {/* è¾“å…¥æ¡† */}
      <div className="input-area">
        <textarea
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyPress={(e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
              e.preventDefault();
              sendMessage();
            }
          }}
          placeholder="è¾“å…¥æ¶ˆæ¯... (Shift+Enter æ¢è¡Œ)"
          disabled={loading}
        />
        <button onClick={sendMessage} disabled={loading || !input.trim()}>
          {loading ? 'å‘é€ä¸­...' : 'å‘é€'}
        </button>
      </div>
    </div>
  );
}

// æ¶ˆæ¯ç»„ä»¶
function Message({ message, streaming }) {
  const isUser = message.role === 'user';

  return (
    <div className={`message ${isUser ? 'user' : 'assistant'}`}>
      <div className="avatar">
        {isUser ? 'ğŸ‘¤' : 'ğŸ¤–'}
      </div>
      <div className="content">
        {isUser ? (
          <div className="text">{message.content}</div>
        ) : (
          <div
            className="text markdown"
            dangerouslySetInnerHTML={{
              __html: marked(message.content)
            }}
          />
        )}
        {streaming && <span className="cursor">â–Š</span>}
      </div>
    </div>
  );
}

export default ChatApp;
```

#### æ ·å¼

```css
/* styles/chat.css */
.chat-container {
  display: flex;
  flex-direction: column;
  height: 100vh;
  max-width: 900px;
  margin: 0 auto;
  background: #fff;
}

.messages {
  flex: 1;
  overflow-y: auto;
  padding: 20px;
  background: #f5f5f5;
}

.message {
  display: flex;
  gap: 12px;
  margin-bottom: 24px;
  animation: slideIn 0.3s ease-out;
}

@keyframes slideIn {
  from {
    opacity: 0;
    transform: translateY(10px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

.message.user {
  flex-direction: row-reverse;
}

.avatar {
  font-size: 32px;
  width: 40px;
  height: 40px;
  flex-shrink: 0;
}

.content {
  max-width: 70%;
  padding: 12px 16px;
  border-radius: 12px;
  position: relative;
}

.message.user .content {
  background: #007bff;
  color: white;
  border-bottom-right-radius: 4px;
}

.message.assistant .content {
  background: white;
  border: 1px solid #e0e0e0;
  border-bottom-left-radius: 4px;
}

.markdown {
  line-height: 1.6;
}

.markdown h1,
.markdown h2,
.markdown h3 {
  margin-top: 16px;
  margin-bottom: 8px;
}

.markdown code {
  background: #f4f4f4;
  padding: 2px 6px;
  border-radius: 3px;
  font-family: 'Courier New', monospace;
  font-size: 0.9em;
}

.markdown pre {
  background: #1e1e1e;
  padding: 16px;
  border-radius: 8px;
  overflow-x: auto;
  margin: 12px 0;
}

.markdown pre code {
  background: none;
  padding: 0;
  color: #d4d4d4;
}

.markdown ul,
.markdown ol {
  padding-left: 24px;
}

.markdown blockquote {
  border-left: 4px solid #ddd;
  padding-left: 16px;
  margin: 12px 0;
  color: #666;
}

.cursor {
  animation: blink 1s infinite;
}

@keyframes blink {
  0%, 50% { opacity: 1; }
  51%, 100% { opacity: 0; }
}

.input-area {
  display: flex;
  gap: 12px;
  padding: 20px;
  background: white;
  border-top: 1px solid #e0e0e0;
}

textarea {
  flex: 1;
  padding: 12px;
  border: 1px solid #ddd;
  border-radius: 8px;
  resize: none;
  font-size: 14px;
  font-family: inherit;
  min-height: 60px;
  max-height: 200px;
}

textarea:focus {
  outline: none;
  border-color: #007bff;
}

textarea:disabled {
  background: #f5f5f5;
  cursor: not-allowed;
}

button {
  padding: 12px 24px;
  background: #007bff;
  color: white;
  border: none;
  border-radius: 8px;
  cursor: pointer;
  font-size: 14px;
  font-weight: 500;
  transition: background 0.2s;
}

button:hover:not(:disabled) {
  background: #0056b3;
}

button:disabled {
  background: #ccc;
  cursor: not-allowed;
}
```

### Vue 3 ä¸­é›†æˆ ChatGPT

```vue
<template>
  <div class="chat-container">
    <!-- æ¶ˆæ¯åˆ—è¡¨ -->
    <div ref="messagesContainer" class="messages">
      <div
        v-for="(msg, index) in displayMessages"
        :key="index"
        :class="['message', msg.role]"
      >
        <div class="avatar">
          {{ msg.role === 'user' ? 'ğŸ‘¤' : 'ğŸ¤–' }}
        </div>
        <div class="content">
          <div v-if="msg.role === 'user'" class="text">
            {{ msg.content }}
          </div>
          <div
            v-else
            class="text markdown"
            v-html="renderMarkdown(msg.content)"
          ></div>
          <span v-if="msg.streaming" class="cursor">â–Š</span>
        </div>
      </div>
    </div>

    <!-- è¾“å…¥æ¡† -->
    <div class="input-area">
      <textarea
        v-model="input"
        @keydown.enter.exact.prevent="sendMessage"
        placeholder="è¾“å…¥æ¶ˆæ¯... (Shift+Enter æ¢è¡Œ)"
        :disabled="loading"
      ></textarea>
      <button @click="sendMessage" :disabled="loading || !input.trim()">
        {{ loading ? 'å‘é€ä¸­...' : 'å‘é€' }}
      </button>
    </div>
  </div>
</template>

<script setup>
import { ref, computed, nextTick, watch } from 'vue';
import { marked } from 'marked';
import hljs from 'highlight.js';

// é…ç½® marked
marked.setOptions({
  highlight: (code, lang) => {
    if (lang && hljs.getLanguage(lang)) {
      return hljs.highlight(code, { language: lang }).value;
    }
    return hljs.highlightAuto(code).value;
  },
  breaks: true,
  gfm: true
});

const messages = ref([
  {
    role: 'system',
    content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‰ç«¯å¼€å‘åŠ©æ‰‹'
  }
]);

const input = ref('');
const loading = ref(false);
const streamingContent = ref('');
const messagesContainer = ref(null);

// æ˜¾ç¤ºçš„æ¶ˆæ¯ï¼ˆåŒ…æ‹¬æµå¼å†…å®¹ï¼‰
const displayMessages = computed(() => {
  const msgs = messages.value.slice(1); // æ’é™¤ system message

  if (streamingContent.value) {
    return [
      ...msgs,
      {
        role: 'assistant',
        content: streamingContent.value,
        streaming: true
      }
    ];
  }

  return msgs;
});

// æ»šåŠ¨åˆ°åº•éƒ¨
const scrollToBottom = () => {
  nextTick(() => {
    if (messagesContainer.value) {
      messagesContainer.value.scrollTop = messagesContainer.value.scrollHeight;
    }
  });
};

// ç›‘å¬æ¶ˆæ¯å˜åŒ–ï¼Œè‡ªåŠ¨æ»šåŠ¨
watch(
  () => [messages.value.length, streamingContent.value],
  () => {
    scrollToBottom();
  }
);

// æ¸²æŸ“ Markdown
const renderMarkdown = (content) => {
  return marked(content);
};

// å‘é€æ¶ˆæ¯
const sendMessage = async () => {
  if (!input.value.trim() || loading.value) return;

  const userMessage = {
    role: 'user',
    content: input.value.trim()
  };

  messages.value.push(userMessage);
  input.value = '';
  loading.value = true;
  streamingContent.value = '';

  try {
    await streamChat(
      messages.value,
      (chunk) => {
        streamingContent.value += chunk;
      },
      () => {
        messages.value.push({
          role: 'assistant',
          content: streamingContent.value
        });
        streamingContent.value = '';
        loading.value = false;
      },
      (error) => {
        console.error('Error:', error);
        messages.value.push({
          role: 'assistant',
          content: 'æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚'
        });
        streamingContent.value = '';
        loading.value = false;
      }
    );
  } catch (error) {
    console.error('Send message error:', error);
    loading.value = false;
    streamingContent.value = '';
  }
};

// æµå¼å“åº”
const streamChat = async (msgs, onChunk, onComplete, onError) => {
  try {
    const response = await fetch('/api/chat/stream', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ messages: msgs })
    });

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }

    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let buffer = '';

    while (true) {
      const { done, value } = await reader.read();
      if (done) {
        onComplete();
        break;
      }

      buffer += decoder.decode(value, { stream: true });
      const lines = buffer.split('\n');
      buffer = lines.pop() || '';

      for (const line of lines) {
        const trimmed = line.trim();
        if (!trimmed || trimmed === 'data: [DONE]') continue;

        if (trimmed.startsWith('data: ')) {
          try {
            const data = JSON.parse(trimmed.slice(6));
            const content = data.choices[0]?.delta?.content;
            if (content) onChunk(content);
          } catch (e) {
            console.error('Parse error:', e);
          }
        }
      }
    }
  } catch (error) {
    onError(error);
  }
};
</script>

<style scoped>
/* ä½¿ç”¨ä¹‹å‰çš„ CSS æ ·å¼ */
</style>
```

### èŠå¤©ç•Œé¢å®ç°

#### æ‰“å­—æœºæ•ˆæœå®ç°

```javascript
/**
 * æ‰“å­—æœºæ•ˆæœç»„ä»¶
 */
import React, { useState, useEffect } from 'react';

function TypewriterText({ text, speed = 30 }) {
  const [displayText, setDisplayText] = useState('');
  const [currentIndex, setCurrentIndex] = useState(0);

  useEffect(() => {
    if (currentIndex < text.length) {
      const timer = setTimeout(() => {
        setDisplayText(prev => prev + text[currentIndex]);
        setCurrentIndex(prev => prev + 1);
      }, speed);

      return () => clearTimeout(timer);
    }
  }, [currentIndex, text, speed]);

  return <span>{displayText}<span className="cursor">â–Š</span></span>;
}

// ä½¿ç”¨
function Message({ content, streaming }) {
  if (streaming) {
    return <TypewriterText text={content} speed={30} />;
  }
  return <div>{content}</div>;
}
```

### Markdown æ¸²æŸ“

å·²åœ¨ä¸Šé¢çš„ç»„ä»¶ä¸­åŒ…å«ï¼Œä½¿ç”¨ `marked` å’Œ `highlight.js`ã€‚

### ä»£ç é«˜äº®

```javascript
import hljs from 'highlight.js';
import 'highlight.js/styles/github-dark.css'; // é€‰æ‹©ä¸»é¢˜

// é…ç½® marked
import { marked } from 'marked';

marked.setOptions({
  highlight: function(code, lang) {
    if (lang && hljs.getLanguage(lang)) {
      try {
        return hljs.highlight(code, { language: lang }).value;
      } catch (err) {
        console.error(err);
      }
    }
    return hljs.highlightAuto(code).value;
  },
  langPrefix: 'hljs language-', // highlight.js css uses this prefix
  breaks: true, // æ”¯æŒ GFM æ¢è¡Œ
  gfm: true // å¯ç”¨ GitHub Flavored Markdown
});
```

---

## å…¶ä»– LLM API

### Claude API

```javascript
import Anthropic from '@anthropic-ai/sdk';

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY
});

async function chatWithClaude(messages) {
  const response = await anthropic.messages.create({
    model: 'claude-3-opus-20240229',
    max_tokens: 1024,
    messages: messages.map(msg => ({
      role: msg.role === 'system' ? 'user' : msg.role,
      content: msg.content
    }))
  });

  return response.content[0].text;
}
```

### æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰

```javascript
async function chatWithErnie(messages) {
  // 1. è·å– access_token
  const authResponse = await fetch(
    `https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id=${API_KEY}&client_secret=${SECRET_KEY}`,
    { method: 'POST' }
  );
  const { access_token } = await authResponse.json();

  // 2. è°ƒç”¨ API
  const response = await fetch(
    `https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions_pro?access_token=${access_token}`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ messages })
    }
  );

  const data = await response.json();
  return data.result;
}
```

### é€šä¹‰åƒé—®ï¼ˆé˜¿é‡Œï¼‰

```javascript
async function chatWithQwen(messages) {
  const response = await fetch(
    'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation',
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${DASHSCOPE_API_KEY}`
      },
      body: JSON.stringify({
        model: 'qwen-max',
        input: {
          messages
        }
      })
    }
  );

  const data = await response.json();
  return data.output.text;
}
```

---

## Token è®¡ç®—å’Œæˆæœ¬æ§åˆ¶

### Token è®¡æ•°

```javascript
import { encoding_for_model } from 'tiktoken';

class TokenCounter {
  constructor(model = 'gpt-4') {
    this.model = model;
    this.encoding = encoding_for_model(model);
  }

  // è®¡ç®—æ–‡æœ¬çš„ token æ•°
  count(text) {
    return this.encoding.encode(text).length;
  }

  // è®¡ç®—æ¶ˆæ¯æ•°ç»„çš„ token æ•°
  countMessages(messages) {
    let total = 3; // æ¯ä¸ªå¯¹è¯éƒ½æœ‰å›ºå®šçš„ 3 ä¸ª token å¼€é”€

    for (const message of messages) {
      total += 3; // æ¯æ¡æ¶ˆæ¯ 3 ä¸ª token
      total += this.count(message.content);

      if (message.name) {
        total += this.count(message.name) + 1;
      }
    }

    return total;
  }

  // é‡Šæ”¾èµ„æº
  free() {
    this.encoding.free();
  }
}

// ä½¿ç”¨
const counter = new TokenCounter('gpt-4');
const tokens = counter.countMessages(messages);
console.log(`Total tokens: ${tokens}`);
counter.free();
```

### æˆæœ¬ä¼°ç®—

```javascript
class CostEstimator {
  constructor() {
    // ä»·æ ¼è¡¨ï¼ˆç¾å…ƒ/1K tokensï¼‰
    this.pricing = {
      'gpt-4': {
        input: 0.03,
        output: 0.06
      },
      'gpt-4-turbo': {
        input: 0.01,
        output: 0.03
      },
      'gpt-3.5-turbo': {
        input: 0.0015,
        output: 0.002
      }
    };
  }

  // ä¼°ç®—å•æ¬¡å¯¹è¯æˆæœ¬
  estimateCost(model, inputTokens, outputTokens) {
    const price = this.pricing[model];
    if (!price) {
      throw new Error(`Unknown model: ${model}`);
    }

    const inputCost = (inputTokens / 1000) * price.input;
    const outputCost = (outputTokens / 1000) * price.output;

    return {
      inputCost,
      outputCost,
      totalCost: inputCost + outputCost,
      inputTokens,
      outputTokens,
      totalTokens: inputTokens + outputTokens
    };
  }

  // æ ¼å¼åŒ–æˆæœ¬
  formatCost(cost) {
    return `$${cost.toFixed(4)}`;
  }
}

// ä½¿ç”¨
const estimator = new CostEstimator();
const cost = estimator.estimateCost('gpt-4', 1000, 500);

console.log(`è¾“å…¥æˆæœ¬: ${estimator.formatCost(cost.inputCost)}`);
console.log(`è¾“å‡ºæˆæœ¬: ${estimator.formatCost(cost.outputCost)}`);
console.log(`æ€»æˆæœ¬: ${estimator.formatCost(cost.totalCost)}`);
```

### æˆæœ¬æ§åˆ¶ç­–ç•¥

```javascript
class CostController {
  constructor(maxTokens = 4000, maxCostPerRequest = 0.1) {
    this.maxTokens = maxTokens;
    this.maxCostPerRequest = maxCostPerRequest;
    this.tokenCounter = new TokenCounter();
    this.costEstimator = new CostEstimator();
  }

  // é™åˆ¶æ¶ˆæ¯å†å²é•¿åº¦
  limitMessages(messages, systemMessage) {
    const result = systemMessage ? [systemMessage] : [];
    let totalTokens = systemMessage ? this.tokenCounter.count(systemMessage.content) : 0;

    // ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹æ·»åŠ 
    for (let i = messages.length - 1; i >= 0; i--) {
      const msg = messages[i];
      const tokens = this.tokenCounter.count(msg.content);

      if (totalTokens + tokens > this.maxTokens) {
        break;
      }

      result.unshift(msg);
      totalTokens += tokens;
    }

    return { messages: result, totalTokens };
  }

  // ä¼°ç®—å¹¶æ§åˆ¶æˆæœ¬
  checkCost(inputTokens, estimatedOutputTokens = 1000) {
    const cost = this.costEstimator.estimateCost(
      'gpt-4',
      inputTokens,
      estimatedOutputTokens
    );

    if (cost.totalCost > this.maxCostPerRequest) {
      throw new Error(
        `é¢„ä¼°æˆæœ¬ ${cost.totalCost.toFixed(4)} è¶…è¿‡é™åˆ¶ ${this.maxCostPerRequest}`
      );
    }

    return cost;
  }
}

// ä½¿ç”¨
const controller = new CostController(4000, 0.1);

// é™åˆ¶æ¶ˆæ¯
const { messages: limited, totalTokens } = controller.limitMessages(
  allMessages,
  systemMessage
);

// æ£€æŸ¥æˆæœ¬
try {
  const cost = controller.checkCost(totalTokens, 1000);
  console.log('é¢„ä¼°æˆæœ¬:', cost);
  // ç»§ç»­è°ƒç”¨ API
} catch (error) {
  console.error('æˆæœ¬è¶…é™:', error.message);
  // æç¤ºç”¨æˆ·æˆ–å‡å°‘ token ä½¿ç”¨
}
```

---

## å®‰å…¨æ³¨æ„äº‹é¡¹

### 1. API Key ä¿æŠ¤

```javascript
// âŒ é”™è¯¯åšæ³•
const OPENAI_API_KEY = 'sk-xxx'; // æ°¸è¿œä¸è¦åœ¨å‰ç«¯ä»£ç ä¸­ç¡¬ç¼–ç 

// âŒ é”™è¯¯åšæ³•
const response = await fetch('https://api.openai.com/v1/chat/completions', {
  headers: {
    'Authorization': `Bearer ${OPENAI_API_KEY}` // æš´éœ²åœ¨å‰ç«¯
  }
});

// âœ… æ­£ç¡®åšæ³•ï¼šä½¿ç”¨åç«¯ä»£ç†
// å‰ç«¯è°ƒç”¨åç«¯
const response = await fetch('/api/chat', {
  method: 'POST',
  body: JSON.stringify({ messages })
});

// åç«¯å­˜å‚¨ API Key
const apiKey = process.env.OPENAI_API_KEY;
```

### 2. è¾“å…¥éªŒè¯å’Œè¿‡æ»¤

```javascript
class InputValidator {
  // éªŒè¯ç”¨æˆ·è¾“å…¥
  validate(input) {
    // 1. é•¿åº¦é™åˆ¶
    if (input.length > 5000) {
      throw new Error('è¾“å…¥è¿‡é•¿');
    }

    // 2. å†…å®¹è¿‡æ»¤ï¼ˆæ•æ„Ÿè¯ï¼‰
    const bannedWords = ['æ•æ„Ÿè¯1', 'æ•æ„Ÿè¯2'];
    for (const word of bannedWords) {
      if (input.includes(word)) {
        throw new Error('è¾“å…¥åŒ…å«æ•æ„Ÿå†…å®¹');
      }
    }

    // 3. æ ¼å¼æ£€æŸ¥
    if (/<script/i.test(input)) {
      throw new Error('è¾“å…¥åŒ…å«ä¸å®‰å…¨å†…å®¹');
    }

    return true;
  }

  // æ¸…ç†è¾“å…¥
  sanitize(input) {
    return input
      .trim()
      .replace(/<script.*?>.*?<\/script>/gi, '') // ç§»é™¤ script æ ‡ç­¾
      .replace(/[<>]/g, ''); // ç§»é™¤å°–æ‹¬å·
  }
}

// ä½¿ç”¨
const validator = new InputValidator();

try {
  validator.validate(userInput);
  const cleanInput = validator.sanitize(userInput);
  // ç»§ç»­å¤„ç†
} catch (error) {
  console.error('è¾“å…¥éªŒè¯å¤±è´¥:', error.message);
}
```

### 3. è®¿é—®æ§åˆ¶å’Œé™æµ

```javascript
// é™æµä¸­é—´ä»¶ï¼ˆExpressï¼‰
import rateLimit from 'express-rate-limit';

const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 åˆ†é’Ÿ
  max: 100, // æœ€å¤š 100 æ¬¡è¯·æ±‚
  message: 'è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•'
});

app.use('/api/chat', limiter);

// ç”¨æˆ·èº«ä»½éªŒè¯
app.post('/api/chat', authenticateUser, async (req, res) => {
  // éªŒè¯ç”¨æˆ·èº«ä»½
  if (!req.user) {
    return res.status(401).json({ error: 'Unauthorized' });
  }

  // æ£€æŸ¥ç”¨æˆ·é…é¢
  const usage = await getUserUsage(req.user.id);
  if (usage > MAX_USAGE) {
    return res.status(429).json({ error: 'Quota exceeded' });
  }

  // ç»§ç»­å¤„ç†
});
```

### 4. è¾“å‡ºè¿‡æ»¤

```javascript
class OutputFilter {
  // è¿‡æ»¤æ•æ„Ÿä¿¡æ¯
  filter(output) {
    // 1. ç§»é™¤å¯èƒ½çš„æ•æ„Ÿæ•°æ®
    return output
      .replace(/\b\d{11}\b/g, '***æ‰‹æœºå·***') // æ‰‹æœºå·
      .replace(/\b\d{15,18}\b/g, '***èº«ä»½è¯***') // èº«ä»½è¯
      .replace(/sk-[a-zA-Z0-9]{48}/g, '***API_KEY***'); // API Key
  }

  // æ£€æµ‹ä¸å½“å†…å®¹
  hasInappropriateContent(output) {
    const patterns = [
      /æš´åŠ›/i,
      /è‰²æƒ…/i,
      // æ›´å¤šæ¨¡å¼...
    ];

    return patterns.some(pattern => pattern.test(output));
  }
}

// ä½¿ç”¨
const filter = new OutputFilter();

let response = await getAIResponse(messages);

// è¿‡æ»¤è¾“å‡º
response = filter.filter(response);

// æ£€æŸ¥å†…å®¹
if (filter.hasInappropriateContent(response)) {
  response = 'æŠ±æ­‰ï¼Œæ— æ³•æä¾›ç›¸å…³å†…å®¹';
}
```

---

## é¢è¯•é¢˜

**1. å¦‚ä½•å®ç° ChatGPT çš„æµå¼å“åº”ï¼Ÿ**

å…³é”®ç‚¹ï¼š
- ä½¿ç”¨ Server-Sent Events (SSE)
- ReadableStream API
- é€å—è§£æå’Œæ˜¾ç¤º

**2. å¦‚ä½•ä¿æŠ¤ API Key ä¸è¢«æ³„éœ²ï¼Ÿ**

ç­”æ¡ˆï¼š
- æ°¸è¿œä¸åœ¨å‰ç«¯æš´éœ² API Key
- ä½¿ç”¨åç«¯ä»£ç†
- ç¯å¢ƒå˜é‡å­˜å‚¨
- è®¿é—®æ§åˆ¶å’Œé™æµ

**3. å¦‚ä½•è®¡ç®—å’Œæ§åˆ¶ API è°ƒç”¨æˆæœ¬ï¼Ÿ**

ç­”æ¡ˆï¼š
- ä½¿ç”¨ tiktoken è®¡ç®— token æ•°
- é™åˆ¶æ¶ˆæ¯å†å²é•¿åº¦
- è®¾ç½®æˆæœ¬ä¸Šé™
- ç›‘æ§ API ä½¿ç”¨æƒ…å†µ

**4. Function Calling çš„åº”ç”¨åœºæ™¯æ˜¯ä»€ä¹ˆï¼Ÿ**

ç­”æ¡ˆï¼š
- è°ƒç”¨å¤–éƒ¨ APIï¼ˆå¤©æ°”ã€æœç´¢ç­‰ï¼‰
- æ•°æ®åº“æŸ¥è¯¢
- æ‰§è¡Œè®¡ç®—
- ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ

**5. å¦‚ä½•ä¼˜åŒ–èŠå¤©åº”ç”¨çš„ç”¨æˆ·ä½“éªŒï¼Ÿ**

ç­”æ¡ˆï¼š
- æµå¼å“åº”ï¼ˆæ‰“å­—æœºæ•ˆæœï¼‰
- Markdown æ¸²æŸ“
- ä»£ç é«˜äº®
- è‡ªåŠ¨æ»šåŠ¨
- åŠ è½½çŠ¶æ€
- é”™è¯¯å¤„ç†

---

## æ€»ç»“

æœ¬æ–‡ä»‹ç»äº†ï¼š
1. OpenAI API çš„å®Œæ•´ä½¿ç”¨æ–¹æ³•
2. æµå¼å“åº”çš„å®ç°
3. Function Calling çš„åº”ç”¨
4. React/Vue é›†æˆå®è·µ
5. Token è®¡ç®—å’Œæˆæœ¬æ§åˆ¶
6. å®‰å…¨æ³¨æ„äº‹é¡¹

æŒæ¡è¿™äº›å†…å®¹ï¼Œä½ å°±èƒ½åœ¨é¡¹ç›®ä¸­æˆåŠŸé›†æˆ ChatGPT å’Œå…¶ä»– LLMï¼
